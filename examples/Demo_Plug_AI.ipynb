{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce172f9e-3dc8-4fd4-b025-f390381438ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Pytorch & Co to Plug_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7f2c8-d7ef-4ec2-a561-38339926788d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using conventionnal Pytorch + MonAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6246509f-4684-4eab-a086-7c0095fb7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926023d7-699c-466b-8364-a3a6e4a449ff",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This cell imports necessary libraries and modules for building a deep learning pipeline with PyTorch and MONAI, including data transformations, the DynUNet model, loss function, metric, and optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b6d59-316d-4d61-9af6-52f00f49c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    EnsureChannelFirstd,\n",
    "    ConcatItemsd,\n",
    "    SpatialCropd,\n",
    "    AsDiscreted\n",
    ")\n",
    "import monai\n",
    "from monai.data import Dataset\n",
    "from monai.networks.nets import DynUNet\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from torch.optim import SGD\n",
    "from monai.utils import set_determinism, first\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4b684-b311-44f1-9764-4e606a20ca94",
   "metadata": {},
   "source": [
    "### Fix random seeds\n",
    "To ensure reproducibility in your experiments using PyTorch and MONAI, you'll want to set seeds for the different random number generators. This includes random seeds for Python's built-in random library, NumPy, PyTorch, and MONAI.\n",
    "\n",
    "Here's an example of how to set seeds for these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f4f56-3bc7-44b3-a1fc-c60e10e11bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    monai.utils.set_determinism(seed)\n",
    "\n",
    "# Set the seed value\n",
    "seed = 42\n",
    "set_all_seeds(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1d507-e9a1-4da2-a394-0e189c64c798",
   "metadata": {},
   "source": [
    "Now you've set the seeds for all the relevant libraries. Remember, even though setting seeds helps improve reproducibility, there still might be some non-deterministic behavior due to GPU operations or other factors outside your control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f80e9d-99e9-45e0-a97c-32151320e402",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This cell defines the data directory, a function to read and process the data list, sets up a data transformation pipeline using MONAI's Compose, and creates a training dataset with the first 20 samples from the data list. The transformation pipeline includes loading images, ensuring channels are in the correct order, concatenating input channels, cropping the input and label, and converting the label to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b5625-9e7d-4589-bd43-eba9bb7c96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/\"\n",
    "\n",
    "def get_datalist(dataset_dir):\n",
    "    datalist = []\n",
    "    with open(os.path.join(dataset_dir, \"train.txt\"), \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            file_dic = {}\n",
    "            files = line.split()\n",
    "            for i, file in enumerate(files[:-1]):\n",
    "                file_dic[f\"channel_{i}\"] = os.path.join(dataset_dir, file)\n",
    "\n",
    "            file_dic[\"label\"] = os.path.join(dataset_dir, files[-1])\n",
    "            datalist.append(file_dic)\n",
    "    return datalist\n",
    "\n",
    "datalist = get_datalist(data_dir)\n",
    "keys = list(datalist[0].keys())\n",
    "\n",
    "transform = Compose([\n",
    "            LoadImaged(keys=keys),\n",
    "            EnsureChannelFirstd(keys=keys),\n",
    "            ConcatItemsd(keys[:-1], \"input\"),\n",
    "            SpatialCropd(keys=['input', 'label'], # crop it to make easily usable for etape 1\n",
    "                         roi_size=[128, 128, 128],\n",
    "                         roi_center=[0, 0, 0]\n",
    "                         ),\n",
    "            AsDiscreted(keys=['label'], to_onehot=5)\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=datalist[:20],\n",
    "                        transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854fb5c-1b16-4e40-b15e-ca363d11f49a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataloader\n",
    "This cell creates a DataLoader for the training dataset, with a batch size of 2, enabling shuffling for random sampling, using 4 worker processes for parallel data loading, and setting a prefetch factor of 10 for efficient data loading in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72233d77-1f65-4045-a3ef-1f4d9daba276",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=2, \n",
    "                          shuffle=True, \n",
    "                          num_workers=4,\n",
    "                         prefetch_factor=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a72bc-21c0-4800-9846-91a02b1e9282",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model\n",
    "This cell initializes the DynUNet model with the specified parameters and moves it to the available device (either GPU or CPU). The model is configured for 3D input, 4 input channels, 5 output channels, custom kernel sizes, strides, upsample kernel sizes, instance normalization, and deep supervision with 3 supervision layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9042dd4-0385-483d-84c7-11046cf197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = DynUNet(spatial_dims = 3,\n",
    "                in_channels = 4,\n",
    "                out_channels = 5,\n",
    "                kernel_size = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]],\n",
    "                strides = [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n",
    "                upsample_kernel_size = [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n",
    "                norm_name = \"instance\",  # you can use fused kernel for normal layer when set to `INSTANCE_NVFUSER`\n",
    "                deep_supervision =  True,\n",
    "                deep_supr_num = 3,).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c571e552-55f1-4aae-a539-30201173810c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Criterion\n",
    "This cell defines a combined Dice loss and cross-entropy loss function using MONAI's DiceCELoss, with one-hot encoding for target labels and softmax activation for the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046dd4aa-61d3-4375-ad36-2bb0ffa83f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceCELoss(to_onehot_y=True, \n",
    "                           softmax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae0bee-0aa1-4020-ad2e-bb62b7353633",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metric\n",
    "This cell defines the evaluation metric as the Dice metric using MONAI's DiceMetric. It excludes the background class and computes the mean Dice score across all classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c7699-a14a-4787-85ed-bd91a2f3d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DiceMetric(include_background=False, \n",
    "                    reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45384e9-6103-440d-881d-bf5db4b76323",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimizer\n",
    "This cell initializes the Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.001 for the model's parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f163b4-405f-42a9-b0b5-8addf8f08890",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd337f55-0c3d-4f6a-9f38-44da7aaabe13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop\n",
    "\n",
    "This cell trains the model for 2 epochs using the DataLoader, model, loss function, and optimizer previously defined. It iterates through the training data, computes the loss, and updates the model parameters. The training loss is accumulated and the average loss for each epoch is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b885f-498f-4d60-ac64-ea67befdd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "val_interval = 2\n",
    "\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"input\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.unbind(outputs, dim=1)[0]\n",
    "        \n",
    "        labels = torch.argmax(labels, dim=1, keepdim=True)\n",
    "        loss = loss_function(outputs, labels)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_dataset) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a9afe-ed3e-4afc-b8fe-10495089f256",
   "metadata": {},
   "source": [
    "## Plug_AI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f8ffd-f609-4812-8469-d29243e32772",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45f6225d-6492-4904-a60f-b9c2069af2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config_demo.yaml\n",
    "# Default config is used even if no config file is specified in CLI. Undefined arguments will take the default values.\n",
    "##################################################################################################\n",
    "####################################### Global arguments : #######################################\n",
    "##################################################################################################\n",
    "config_file: null\n",
    "export_config: null\n",
    "mode: TRAINING # Choose between Training, Evaluation, Inference\n",
    "verbose: FULL #Full, Restricted, None\n",
    "seed: null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b114e-5eed-4ae5-b5b2-0dccaf961817",
   "metadata": {},
   "source": [
    "### Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61b5193f-1b70-4725-9d9b-d5fed1b25e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config_demo.yaml\n",
    "##################################################################################################\n",
    "######################################## Data arguments : ########################################\n",
    "##################################################################################################\n",
    "dataset: MedNIST\n",
    "dataset_kwargs:\n",
    "    dataset_dir: /gpfswork/rech/ibu/commun/datasets/MedNIST # Absolute path to the dataset root dir\n",
    "    download_dataset: false\n",
    "    transformation: MedNIST_transform\n",
    "preprocess: null\n",
    "preprocess_kwargs:\n",
    "train_ratio: 1 #How to specify the split? Train ratio => Dataset => train+val (train_ratio) | test (1 - train_ratio)\n",
    "val_ratio: 0.2 #A subfraction of the train set to use for validation (train_ratio * val_ratio = val_real_ratio)\n",
    "limit_sample: 20\n",
    "batch_size: 2\n",
    "shuffle: true\n",
    "drop_last: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85217f66-f708-4e55-b1a7-514deb974648",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "780d317d-46ca-433c-b8ca-b06c0d5e3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config_demo.yaml\n",
    "##################################################################################################\n",
    "####################################### Model arguments : ########################################\n",
    "##################################################################################################\n",
    "model: DenseNet     #model_type MODEL_TYPE\n",
    "model_kwargs:     #model_args MODEL_ARGS\n",
    "    spatial_dims: 2\n",
    "    in_channels: 1\n",
    "    out_channels: 6\n",
    "    img_size: 64    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c7178-6e94-4fbd-8234-36b6e3cd13da",
   "metadata": {},
   "source": [
    "### Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "461f070b-6c2d-4fe0-829c-82a7d89341ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config_demo.yaml\n",
    "##################################################################################################\n",
    "##################################### Execution arguments : ######################################\n",
    "##################################################################################################\n",
    "#Training settings\n",
    "nb_epoch: 2\n",
    "device: cuda\n",
    "random_seed: 2022  # None for real randomness, set an integer for reproductibility\n",
    "report_log: False\n",
    "\n",
    "loop: Default\n",
    "optimizer: SGD\n",
    "optimizer_kwargs:\n",
    "    lr: 0.0001\n",
    "    momentum: 0.99\n",
    "    weight_decay: 3e-5\n",
    "    nesterov: True\n",
    "lr_scheduler: None\n",
    "lr_scheduler_kwargs:\n",
    "    step_size: 2\n",
    "    verbose: True\n",
    "\n",
    "criterion: DiceCELoss\n",
    "criterion_kwargs:\n",
    "    to_onehot_y: False\n",
    "    softmax: True\n",
    "\n",
    "metric: None\n",
    "metric_kwargs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7931b-2114-442d-ad7b-5ad6f84146d6",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75d64c3-5a9b-4882-bfa9-bf7a092401e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/pytorch-gpu-1.10.1+py3.9.7/bin/python: No module named plug_ai\n"
     ]
    }
   ],
   "source": [
    "!python -m plug_ai --config_file config_demo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9452ba7-de28-4d95-97b8-f76ff7363e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep plug_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bdbc68-222b-4ef5-abfe-62dbef023de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.10.1_py3.9.7",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.10.1_py3.9.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
