{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce172f9e-3dc8-4fd4-b025-f390381438ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Pytorch & Co to Plug_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7f2c8-d7ef-4ec2-a561-38339926788d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using conventionnal Pytorch + MonAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6246509f-4684-4eab-a086-7c0095fb7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 19 02:40:22 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    44W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926023d7-699c-466b-8364-a3a6e4a449ff",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This cell imports necessary libraries and modules for building a deep learning pipeline with PyTorch and MONAI, including data transformations, the DynUNet model, loss function, metric, and optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b6d59-316d-4d61-9af6-52f00f49c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    EnsureChannelFirstd,\n",
    "    ConcatItemsd,\n",
    "    SpatialCropd,\n",
    "    AsDiscreted\n",
    ")\n",
    "import monai\n",
    "from monai.data import Dataset\n",
    "from monai.networks.nets import DynUNet\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from torch.optim import SGD\n",
    "from monai.utils import set_determinism, first\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4b684-b311-44f1-9764-4e606a20ca94",
   "metadata": {},
   "source": [
    "### Fix random seeds\n",
    "To ensure reproducibility in your experiments using PyTorch and MONAI, you'll want to set seeds for the different random number generators. This includes random seeds for Python's built-in random library, NumPy, PyTorch, and MONAI.\n",
    "\n",
    "Here's an example of how to set seeds for these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f4f56-3bc7-44b3-a1fc-c60e10e11bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    monai.utils.set_determinism(seed)\n",
    "\n",
    "# Set the seed value\n",
    "seed = 42\n",
    "set_all_seeds(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1d507-e9a1-4da2-a394-0e189c64c798",
   "metadata": {},
   "source": [
    "Now you've set the seeds for all the relevant libraries. Remember, even though setting seeds helps improve reproducibility, there still might be some non-deterministic behavior due to GPU operations or other factors outside your control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f80e9d-99e9-45e0-a97c-32151320e402",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This cell defines the data directory, a function to read and process the data list, sets up a data transformation pipeline using MONAI's Compose, and creates a training dataset with the first 20 samples from the data list. The transformation pipeline includes loading images, ensuring channels are in the correct order, concatenating input channels, cropping the input and label, and converting the label to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b5625-9e7d-4589-bd43-eba9bb7c96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/\"\n",
    "\n",
    "def get_datalist(dataset_dir):\n",
    "    datalist = []\n",
    "    with open(os.path.join(dataset_dir, \"train.txt\"), \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            file_dic = {}\n",
    "            files = line.split()\n",
    "            for i, file in enumerate(files[:-1]):\n",
    "                file_dic[f\"channel_{i}\"] = os.path.join(dataset_dir, file)\n",
    "\n",
    "            file_dic[\"label\"] = os.path.join(dataset_dir, files[-1])\n",
    "            datalist.append(file_dic)\n",
    "    return datalist\n",
    "\n",
    "datalist = get_datalist(data_dir)\n",
    "keys = list(datalist[0].keys())\n",
    "\n",
    "transform = Compose([\n",
    "            LoadImaged(keys=keys),\n",
    "            EnsureChannelFirstd(keys=keys),\n",
    "            ConcatItemsd(keys[:-1], \"input\"),\n",
    "            SpatialCropd(keys=['input', 'label'], # crop it to make easily usable for etape 1\n",
    "                         roi_size=[128, 128, 128],\n",
    "                         roi_center=[0, 0, 0]\n",
    "                         ),\n",
    "            AsDiscreted(keys=['label'], to_onehot=5)\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=datalist[:20],\n",
    "                        transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854fb5c-1b16-4e40-b15e-ca363d11f49a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataloader\n",
    "This cell creates a DataLoader for the training dataset, with a batch size of 2, enabling shuffling for random sampling, using 4 worker processes for parallel data loading, and setting a prefetch factor of 10 for efficient data loading in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72233d77-1f65-4045-a3ef-1f4d9daba276",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=2, \n",
    "                          shuffle=True, \n",
    "                          num_workers=4,\n",
    "                         prefetch_factor=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a72bc-21c0-4800-9846-91a02b1e9282",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model\n",
    "This cell initializes the DynUNet model with the specified parameters and moves it to the available device (either GPU or CPU). The model is configured for 3D input, 4 input channels, 5 output channels, custom kernel sizes, strides, upsample kernel sizes, instance normalization, and deep supervision with 3 supervision layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9042dd4-0385-483d-84c7-11046cf197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = DynUNet(spatial_dims = 3,\n",
    "                in_channels = 4,\n",
    "                out_channels = 5,\n",
    "                kernel_size = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]],\n",
    "                strides = [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n",
    "                upsample_kernel_size = [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n",
    "                norm_name = \"instance\",  # you can use fused kernel for normal layer when set to `INSTANCE_NVFUSER`\n",
    "                deep_supervision =  True,\n",
    "                deep_supr_num = 3,).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c571e552-55f1-4aae-a539-30201173810c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Criterion\n",
    "This cell defines a combined Dice loss and cross-entropy loss function using MONAI's DiceCELoss, with one-hot encoding for target labels and softmax activation for the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046dd4aa-61d3-4375-ad36-2bb0ffa83f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceCELoss(to_onehot_y=True, \n",
    "                           softmax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae0bee-0aa1-4020-ad2e-bb62b7353633",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metric\n",
    "This cell defines the evaluation metric as the Dice metric using MONAI's DiceMetric. It excludes the background class and computes the mean Dice score across all classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c7699-a14a-4787-85ed-bd91a2f3d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DiceMetric(include_background=False, \n",
    "                    reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45384e9-6103-440d-881d-bf5db4b76323",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimizer\n",
    "This cell initializes the Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.001 for the model's parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f163b4-405f-42a9-b0b5-8addf8f08890",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd337f55-0c3d-4f6a-9f38-44da7aaabe13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop\n",
    "\n",
    "This cell trains the model for 2 epochs using the DataLoader, model, loss function, and optimizer previously defined. It iterates through the training data, computes the loss, and updates the model parameters. The training loss is accumulated and the average loss for each epoch is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b885f-498f-4d60-ac64-ea67befdd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "val_interval = 2\n",
    "\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"input\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.unbind(outputs, dim=1)[0]\n",
    "        \n",
    "        labels = torch.argmax(labels, dim=1, keepdim=True)\n",
    "        loss = loss_function(outputs, labels)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_dataset) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a9afe-ed3e-4afc-b8fe-10495089f256",
   "metadata": {},
   "source": [
    "## Plug_AI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f8ffd-f609-4812-8469-d29243e32772",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45f6225d-6492-4904-a60f-b9c2069af2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config_demo.yaml\n",
    "# Default config is used even if no config file is specified in CLI. Undefined arguments will take the default values.\n",
    "##################################################################################################\n",
    "####################################### Global arguments : #######################################\n",
    "##################################################################################################\n",
    "config_file: null\n",
    "export_config: null\n",
    "mode: TRAINING # Choose between Training, Evaluation, Inference\n",
    "verbose: FULL #Full, Restricted, None\n",
    "seed: null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b114e-5eed-4ae5-b5b2-0dccaf961817",
   "metadata": {},
   "source": [
    "### Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61b5193f-1b70-4725-9d9b-d5fed1b25e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config_demo.yaml\n",
    "##################################################################################################\n",
    "######################################## Data arguments : ########################################\n",
    "##################################################################################################\n",
    "dataset: MedNIST\n",
    "dataset_kwargs:\n",
    "    dataset_dir: /gpfswork/rech/ibu/commun/datasets/MedNIST # Absolute path to the dataset root dir\n",
    "    download_dataset: false\n",
    "    transformation: MedNIST_transform\n",
    "preprocess: null\n",
    "preprocess_kwargs:\n",
    "train_ratio: 1 #How to specify the split? Train ratio => Dataset => train+val (train_ratio) | test (1 - train_ratio)\n",
    "val_ratio: 0.2 #A subfraction of the train set to use for validation (train_ratio * val_ratio = val_real_ratio)\n",
    "limit_sample: 20\n",
    "batch_size: 2\n",
    "shuffle: true\n",
    "drop_last: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85217f66-f708-4e55-b1a7-514deb974648",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "780d317d-46ca-433c-b8ca-b06c0d5e3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config_demo.yaml\n",
    "##################################################################################################\n",
    "####################################### Model arguments : ########################################\n",
    "##################################################################################################\n",
    "model: DenseNet     #model_type MODEL_TYPE\n",
    "model_kwargs:     #model_args MODEL_ARGS\n",
    "    spatial_dims: 2\n",
    "    in_channels: 1\n",
    "    out_channels: 6\n",
    "    img_size: 64    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c7178-6e94-4fbd-8234-36b6e3cd13da",
   "metadata": {},
   "source": [
    "### Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "461f070b-6c2d-4fe0-829c-82a7d89341ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to config_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a config_demo.yaml\n",
    "##################################################################################################\n",
    "##################################### Execution arguments : ######################################\n",
    "##################################################################################################\n",
    "#Training settings\n",
    "nb_epoch: 2\n",
    "device: cuda\n",
    "random_seed: 2022  # None for real randomness, set an integer for reproductibility\n",
    "report_log: False\n",
    "\n",
    "loop: Default\n",
    "optimizer: SGD\n",
    "optimizer_kwargs:\n",
    "    lr: 0.0001\n",
    "    momentum: 0.99\n",
    "    weight_decay: 3e-5\n",
    "    nesterov: True\n",
    "lr_scheduler: None\n",
    "lr_scheduler_kwargs:\n",
    "    step_size: 2\n",
    "    verbose: True\n",
    "\n",
    "criterion: DiceCELoss\n",
    "criterion_kwargs:\n",
    "    to_onehot_y: False\n",
    "    softmax: True\n",
    "\n",
    "metric: None\n",
    "metric_kwargs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7931b-2114-442d-ad7b-5ad6f84146d6",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d75d64c3-5a9b-4882-bfa9-bf7a092401e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfsdswork/projects/rech/ibu/ssos023/Plug-AI/examples/config_demo.yaml\n",
      "Plug-AI running with config:\n",
      "\t dataset : MedNIST\n",
      "\t dataset_kwargs : {'dataset_dir': '/gpfswork/rech/ibu/commun/datasets/MedNIST', 'download_dataset': False, 'transformation': 'MedNIST_transform'}\n",
      "\t model : DenseNet\n",
      "\t model_kwargs : {'spatial_dims': 2, 'in_channels': 1, 'out_channels': 6, 'img_size': 64}\n",
      "\t nb_epoch : 2\n",
      "\t learning_rate : 5e-05\n",
      "\t device : cuda\n",
      "\t random_seed : 2022\n",
      "\t report_log : False\n",
      "\t loop : Default\n",
      "\t loop_kwargs : {'nnunet_dataset_rootdir': '/gpfswork/rech/ibu/commun/nnUNet_experiment_kg/nnUNet_raw_data_base', 'nnunet_preprocessed_rootdir': '/gpfswork/rech/ibu/commun/nnUNet_experiment_kg/nnUNet_preprocessed', 'nnunet_experiment_dir': '/gpfswork/rech/ibu/commun/nnUNet_experiment_kg/nnUNet_preprocessed', 'network': '2d', 'network_trainer': 'nnUNetTrainerV2', 'task': 4, 'fold': 'all'}\n",
      "\t lr_scheduler : None\n",
      "\t lr_scheduler_kwargs : {'step_size': 2, 'verbose': True}\n",
      "\t config_file : config_demo.yaml\n",
      "\t export_config : None\n",
      "\t mode : TRAINING\n",
      "\t verbose : FULL\n",
      "\t seed : None\n",
      "\t preprocess : None\n",
      "\t preprocess_kwargs : None\n",
      "\t train_ratio : 1\n",
      "\t val_ratio : 0.2\n",
      "\t limit_sample : 20\n",
      "\t batch_size : 2\n",
      "\t shuffle : True\n",
      "\t drop_last : True\n",
      "\t optimizer : SGD\n",
      "\t optimizer_kwargs : {'lr': 0.0001, 'momentum': 0.99, 'weight_decay': 3e-05, 'nesterov': True}\n",
      "\t criterion : DiceCELoss\n",
      "\t criterion_kwargs : {'to_onehot_y': False, 'softmax': True}\n",
      "\t metric : None\n",
      "\t metric_kwargs : None\n",
      "==================================== Dataset initialization ... ====================================\n",
      "Running with interpreted config:\n",
      "\t {'dataset': 'MedNIST', 'dataset_kwargs': {'dataset_dir': '/gpfswork/rech/ibu/commun/datasets/MedNIST', 'download_dataset': False, 'transformation': 'MedNIST_transform'}, 'preprocess': None, 'preprocess_kwargs': {}, 'mode': 'TRAINING', 'batch_size': 2, 'train_ratio': 1.0, 'val_ratio': 0.2, 'limit_sample': 20, 'shuffle': True, 'drop_last': True, 'seed': None, 'verbose': 'FULL'}\n",
      "Dataset type is valid\n",
      "loading dataset...\n",
      "got datalist, extract: \n",
      " {'input': '/gpfswork/rech/ibu/commun/datasets/MedNIST/AbdomenCT/001367.jpeg', 'label': 0}\n",
      "keys: ['input', 'label']\n",
      "MedNIST\n",
      "Loaded the dataset\n",
      "Using  20 elements of the full Dataset.\n",
      "Train, Val, Test sizes :  16 4 0\n",
      "===================================== Model initialization ... =====================================\n",
      "Running with interpreted config:\n",
      "\t {'model': 'DenseNet', 'model_kwargs': {'spatial_dims': 2, 'in_channels': 1, 'out_channels': 6, 'img_size': 64}, 'device': 'cuda', 'mode': 'TRAINING', 'verbose': 'FULL', 'model_name': 'DenseNet'}\n",
      "Model type is valid\n",
      "Model preparation done!\n",
      "=================================== Execution initialization ... ===================================\n",
      "Running with interpreted config:\n",
      "\t {'loop': <class 'plug_ai.runners.trainer.Default_Trainer'>, 'loop_kwargs': {'nnunet_dataset_rootdir': '/gpfswork/rech/ibu/commun/nnUNet_experiment_kg/nnUNet_raw_data_base', 'nnunet_preprocessed_rootdir': '/gpfswork/rech/ibu/commun/nnUNet_experiment_kg/nnUNet_preprocessed', 'nnunet_experiment_dir': '/gpfswork/rech/ibu/commun/nnUNet_experiment_kg/nnUNet_preprocessed', 'network': '2d', 'network_trainer': 'nnUNetTrainerV2', 'task': 4, 'fold': 'all'}, 'mode': 'TRAINING', 'nb_epoch': 2, 'device': 'cuda', 'seed': None, 'report_log': False, 'criterion': <class 'monai.losses.dice.DiceCELoss'>, 'metric': None, 'criterion_kwargs': {'to_onehot_y': False, 'softmax': True}, 'metric_kwargs': {}, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer_kwargs': {'lr': 0.0001, 'momentum': 0.99, 'weight_decay': 3e-05, 'nesterov': True}, 'lr_scheduler': {'scheduler': None, 'scheduler_update': None}, 'lr_scheduler_kwargs': {'step_size': 2, 'verbose': True}, 'verbose': 'FULL', 'dataset_manager': <plug_ai.managers.managers.DatasetManager object at 0x14a58ace3fa0>, 'model_manager': <plug_ai.managers.managers.ModelManager object at 0x14a58ace3ee0>}\n",
      "TRAINING MODE : \n",
      "dict_keys(['lr_scheduler_kwargs', 'lr_scheduler', 'val_loader', 'optimizer_kwargs', 'optimizer', 'criterion', 'metric_kwargs', 'train_loader', 'verbose', 'criterion_kwargs', 'nb_epoch', 'device', 'metric', 'model'])\n",
      "Training ...\n",
      "Criterion is : DiceCELoss(\n",
      "  (dice): DiceLoss()\n",
      "  (cross_entropy): CrossEntropyLoss()\n",
      ")\n",
      "Metric is : None\n",
      "Optimizer is : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.99\n",
      "    nesterov: True\n",
      "    weight_decay: 3e-05\n",
      ")\n",
      "Learning Rate Scheduler is : None\n",
      "start training loop, 8 steps per epoch\n",
      "/linkhome/idris/genidr/ssos023/.local/lib/python3.9/site-packages/monai/losses/dice.py:708: UserWarning: Multichannel targets are not supported in this older Pytorch version 1.10.0a0+git302ee7b. Using argmax (as a workaround) to convert target to a single channel.\n",
      "  warnings.warn(\n",
      "[Epoch 1/2 |  Step_Epoch 1/8 | Loss 2.7218546867370605]\n",
      "[Epoch 1/2 |  Step_Epoch 2/8 | Loss 2.737842321395874]\n",
      "[Epoch 1/2 |  Step_Epoch 3/8 | Loss 2.655136823654175]\n",
      "[Epoch 1/2 |  Step_Epoch 4/8 | Loss 2.570997714996338]\n",
      "[Epoch 1/2 |  Step_Epoch 5/8 | Loss 2.444728374481201]\n",
      "[Epoch 1/2 |  Step_Epoch 6/8 | Loss 2.3598673343658447]\n",
      "[Epoch 1/2 |  Step_Epoch 7/8 | Loss 2.225794792175293]\n",
      "[Epoch 1/2 |  Step_Epoch 8/8 | Loss 2.0706114768981934]\n",
      "Epoch 0 finished\n",
      "[Epoch 2/2 |  Step_Epoch 1/8 | Loss 1.9333223104476929]\n",
      "[Epoch 2/2 |  Step_Epoch 2/8 | Loss 1.7328038215637207]\n",
      "[Epoch 2/2 |  Step_Epoch 3/8 | Loss 1.541804552078247]\n",
      "[Epoch 2/2 |  Step_Epoch 4/8 | Loss 1.3802597522735596]\n",
      "[Epoch 2/2 |  Step_Epoch 5/8 | Loss 1.1969120502471924]\n",
      "[Epoch 2/2 |  Step_Epoch 6/8 | Loss 1.0626246929168701]\n",
      "[Epoch 2/2 |  Step_Epoch 7/8 | Loss 0.8840490579605103]\n",
      "[Epoch 2/2 |  Step_Epoch 8/8 | Loss 0.699912965297699]\n",
      "Epoch 1 finished\n",
      "Execution over\n",
      ">>> Complete execution in: 0:00:05.200356\n"
     ]
    }
   ],
   "source": [
    "!python -m plug_ai --config_file config_demo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9452ba7-de28-4d95-97b8-f76ff7363e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.10.1_py3.9.7",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.10.1_py3.9.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
