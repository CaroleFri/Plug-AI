{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89e04a8-e34c-4901-b787-448f0e92a0aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test CLI APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e9a20-5e8e-4c29-823b-5bfb6a3b7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cef5c5-d61c-46e2-a9aa-b48edb49dff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CLI run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0d9198-841b-4f02-87e4-dc0bfa0ed26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfsdswork/projects/rech/ibu/ssos023/Plug-AI/config_exemples/config_Brats.yaml\n",
      "Plug-AI running with config:\n",
      "\t dataset : BraTS\n",
      "\t dataset_kwargs : {'dataset_dir': '/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/', 'download_dataset': False, 'transformation': 'BraTS_transform'}\n",
      "\t model : DynUnet\n",
      "\t model_kwargs : {'checkpoint_path': './model_checkpoint', 'res_out': False, 'use_signature': False}\n",
      "\t nb_epoch : 10\n",
      "\t learning_rate : 5e-05\n",
      "\t device : cuda\n",
      "\t random_seed : 2022\n",
      "\t report_log : False\n",
      "\t loop : Default\n",
      "\t loop_kwargs : {'step': 'Default', 'step_kwargs': None}\n",
      "\t lr_scheduler : None\n",
      "\t lr_scheduler_kwargs : {'step_size': 2, 'verbose': True}\n",
      "\t config_file : ../config_exemples/config_Brats.yaml\n",
      "\t export_config : None\n",
      "\t mode : TRAINING\n",
      "\t verbose : FULL\n",
      "\t seed : None\n",
      "\t preprocess : None\n",
      "\t preprocess_kwargs : None\n",
      "\t generate_signature : True\n",
      "\t train_ratio : 1\n",
      "\t val_ratio : 0.2\n",
      "\t limit_sample : 20\n",
      "\t batch_size : 2\n",
      "\t shuffle : True\n",
      "\t drop_last : True\n",
      "\t optimizer : SGD\n",
      "\t optimizer_kwargs : {'lr': 0.0001, 'momentum': 0.99, 'weight_decay': 3e-05, 'nesterov': True}\n",
      "\t criterion : DiceCELoss\n",
      "\t criterion_kwargs : {'to_onehot_y': False, 'softmax': True}\n",
      "\t metric : MeanDice\n",
      "\t metric_kwargs : None\n",
      "==================================== Dataset initialization ... ====================================\n",
      "Running with interpreted config:\n",
      "\t {'dataset': 'BraTS', 'dataset_kwargs': {'dataset_dir': '/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/', 'download_dataset': False, 'transformation': 'BraTS_transform'}, 'preprocess': None, 'preprocess_kwargs': {}, 'mode': 'TRAINING', 'batch_size': 2, 'train_ratio': 1.0, 'val_ratio': 0.2, 'limit_sample': 20, 'shuffle': True, 'drop_last': True, 'seed': None, 'verbose': 'FULL'}\n",
      "Dataset type is valid\n",
      "loading dataset...\n",
      "got datalist, extract: \n",
      " {'channel_0': '/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/BraTS2021_00081/BraTS2021_00081_flair.nii.gz', 'channel_1': '/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/BraTS2021_00081/BraTS2021_00081_t1ce.nii.gz', 'channel_2': '/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/BraTS2021_00081/BraTS2021_00081_t2.nii.gz', 'channel_3': '/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/BraTS2021_00081/BraTS2021_00081_t1.nii.gz', 'label': '/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/BraTS2021_00081/BraTS2021_00081_seg.nii.gz'}\n",
      "keys: ['channel_0', 'channel_1', 'channel_2', 'channel_3', 'label']\n",
      "BraTS\n",
      "Loaded the dataset\n",
      "Using  20 elements of the full Dataset.\n",
      "Train, Val, Test sizes :  16 4 0\n",
      "===================================== Model initialization ... =====================================\n",
      "Running with interpreted config:\n",
      "\t {'model': 'DynUnet', 'model_kwargs': {'checkpoint_path': './model_checkpoint', 'res_out': False, 'use_signature': False}, 'device': 'cuda', 'mode': 'TRAINING', 'verbose': 'FULL', 'model_name': 'DynUnet'}\n",
      "Model type is valid\n",
      "Model preparation done!\n",
      "=================================== Execution initialization ... ===================================\n",
      "Running with interpreted config:\n",
      "\t {'loop': <class 'plug_ai.runners.trainer.Default_Trainer'>, 'loop_kwargs': {'step': 'Default', 'step_kwargs': None}, 'mode': 'TRAINING', 'nb_epoch': 10, 'device': 'cuda', 'seed': None, 'report_log': False, 'criterion': <class 'monai.losses.dice.DiceCELoss'>, 'metric': <class 'monai.metrics.meandice.DiceMetric'>, 'criterion_kwargs': {'to_onehot_y': False, 'softmax': True}, 'metric_kwargs': {}, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'optimizer_kwargs': {'lr': 0.0001, 'momentum': 0.99, 'weight_decay': 3e-05, 'nesterov': True}, 'lr_scheduler': {'scheduler': None, 'scheduler_update': None}, 'lr_scheduler_kwargs': {'step_size': 2, 'verbose': True}, 'verbose': 'FULL', 'dataset_manager': <plug_ai.managers.managers.DatasetManager object at 0x146109ee0a60>, 'model_manager': <plug_ai.managers.managers.ModelManager object at 0x14610b0720d0>}\n",
      "TRAINING MODE : \n",
      "dict_keys(['lr_scheduler', 'criterion', 'optimizer_kwargs', 'lr_scheduler_kwargs', 'nb_epoch', 'criterion_kwargs', 'device', 'step_kwargs', 'model', 'metric_kwargs', 'val_loader', 'verbose', 'train_loader', 'optimizer', 'metric'])\n",
      "Training ...\n",
      "Criterion is : DiceCELoss(\n",
      "  (dice): DiceLoss()\n",
      "  (cross_entropy): CrossEntropyLoss()\n",
      ")\n",
      "Metric is : <monai.metrics.meandice.DiceMetric object at 0x145fc32eed90>\n",
      "Optimizer is : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.99\n",
      "    nesterov: True\n",
      "    weight_decay: 3e-05\n",
      ")\n",
      "Learning Rate Scheduler is : None\n",
      "start training loop, 8 steps per epoch\n",
      "/linkhome/idris/genidr/ssos023/.local/lib/python3.9/site-packages/monai/losses/dice.py:708: UserWarning: Multichannel targets are not supported in this older Pytorch version 1.10.0a0+git302ee7b. Using argmax (as a workaround) to convert target to a single channel.\n",
      "  warnings.warn(\n",
      "[Epoch 1/10 |  Step_Epoch 1/8 | Loss 2.605746269226074]\n",
      "[Epoch 1/10 |  Step_Epoch 2/8 | Loss 2.584510564804077]\n",
      "[Epoch 1/10 |  Step_Epoch 3/8 | Loss 2.6015777587890625]\n",
      "[Epoch 1/10 |  Step_Epoch 4/8 | Loss 2.6024417877197266]\n",
      "[Epoch 1/10 |  Step_Epoch 5/8 | Loss 2.5826058387756348]\n",
      "[Epoch 1/10 |  Step_Epoch 6/8 | Loss 2.5869827270507812]\n",
      "[Epoch 1/10 |  Step_Epoch 7/8 | Loss 2.5928187370300293]\n",
      "[Epoch 1/10 |  Step_Epoch 8/8 | Loss 2.5843844413757324]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 0 finished\n",
      "[Epoch 2/10 |  Step_Epoch 1/8 | Loss 2.566537857055664]\n",
      "[Epoch 2/10 |  Step_Epoch 2/8 | Loss 2.5747127532958984]\n",
      "[Epoch 2/10 |  Step_Epoch 3/8 | Loss 2.570178270339966]\n",
      "[Epoch 2/10 |  Step_Epoch 4/8 | Loss 2.559680223464966]\n",
      "[Epoch 2/10 |  Step_Epoch 5/8 | Loss 2.5313029289245605]\n",
      "[Epoch 2/10 |  Step_Epoch 6/8 | Loss 2.551710605621338]\n",
      "[Epoch 2/10 |  Step_Epoch 7/8 | Loss 2.54068922996521]\n",
      "[Epoch 2/10 |  Step_Epoch 8/8 | Loss 2.517300605773926]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 1 finished\n",
      "[Epoch 3/10 |  Step_Epoch 1/8 | Loss 2.5007424354553223]\n",
      "[Epoch 3/10 |  Step_Epoch 2/8 | Loss 2.5016839504241943]\n",
      "[Epoch 3/10 |  Step_Epoch 3/8 | Loss 2.4947948455810547]\n",
      "[Epoch 3/10 |  Step_Epoch 4/8 | Loss 2.5114810466766357]\n",
      "[Epoch 3/10 |  Step_Epoch 5/8 | Loss 2.479861259460449]\n",
      "[Epoch 3/10 |  Step_Epoch 6/8 | Loss 2.4667840003967285]\n",
      "[Epoch 3/10 |  Step_Epoch 7/8 | Loss 2.450657606124878]\n",
      "[Epoch 3/10 |  Step_Epoch 8/8 | Loss 2.4563183784484863]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0157])\n",
      "Epoch 2 finished\n",
      "[Epoch 4/10 |  Step_Epoch 1/8 | Loss 2.405715227127075]\n",
      "[Epoch 4/10 |  Step_Epoch 2/8 | Loss 2.4356391429901123]\n",
      "[Epoch 4/10 |  Step_Epoch 3/8 | Loss 2.408639430999756]\n",
      "[Epoch 4/10 |  Step_Epoch 4/8 | Loss 2.4215221405029297]\n",
      "[Epoch 4/10 |  Step_Epoch 5/8 | Loss 2.3774094581604004]\n",
      "[Epoch 4/10 |  Step_Epoch 6/8 | Loss 2.3641514778137207]\n",
      "[Epoch 4/10 |  Step_Epoch 7/8 | Loss 2.3567416667938232]\n",
      "[Epoch 4/10 |  Step_Epoch 8/8 | Loss 2.36324143409729]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0157])\n",
      "Epoch 3 finished\n",
      "[Epoch 5/10 |  Step_Epoch 1/8 | Loss 2.3303182125091553]\n",
      "[Epoch 5/10 |  Step_Epoch 2/8 | Loss 2.323652744293213]\n",
      "[Epoch 5/10 |  Step_Epoch 3/8 | Loss 2.3178317546844482]\n",
      "[Epoch 5/10 |  Step_Epoch 4/8 | Loss 2.2856664657592773]\n",
      "[Epoch 5/10 |  Step_Epoch 5/8 | Loss 2.2841410636901855]\n",
      "[Epoch 5/10 |  Step_Epoch 6/8 | Loss 2.289811372756958]\n",
      "[Epoch 5/10 |  Step_Epoch 7/8 | Loss 2.254533052444458]\n",
      "[Epoch 5/10 |  Step_Epoch 8/8 | Loss 2.2308154106140137]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 4 finished\n",
      "[Epoch 6/10 |  Step_Epoch 1/8 | Loss 2.250330686569214]\n",
      "[Epoch 6/10 |  Step_Epoch 2/8 | Loss 2.194875717163086]\n",
      "[Epoch 6/10 |  Step_Epoch 3/8 | Loss 2.217092514038086]\n",
      "[Epoch 6/10 |  Step_Epoch 4/8 | Loss 2.206512451171875]\n",
      "[Epoch 6/10 |  Step_Epoch 5/8 | Loss 2.144423246383667]\n",
      "[Epoch 6/10 |  Step_Epoch 6/8 | Loss 2.155946969985962]\n",
      "[Epoch 6/10 |  Step_Epoch 7/8 | Loss 2.164022922515869]\n",
      "[Epoch 6/10 |  Step_Epoch 8/8 | Loss 2.1315600872039795]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 5 finished\n",
      "[Epoch 7/10 |  Step_Epoch 1/8 | Loss 2.1109111309051514]\n",
      "[Epoch 7/10 |  Step_Epoch 2/8 | Loss 2.115431308746338]\n",
      "[Epoch 7/10 |  Step_Epoch 3/8 | Loss 2.1074070930480957]\n",
      "[Epoch 7/10 |  Step_Epoch 4/8 | Loss 2.087124824523926]\n",
      "[Epoch 7/10 |  Step_Epoch 5/8 | Loss 2.0367674827575684]\n",
      "[Epoch 7/10 |  Step_Epoch 6/8 | Loss 2.049199104309082]\n",
      "[Epoch 7/10 |  Step_Epoch 7/8 | Loss 2.0271193981170654]\n",
      "[Epoch 7/10 |  Step_Epoch 8/8 | Loss 2.0563857555389404]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 6 finished\n",
      "[Epoch 8/10 |  Step_Epoch 1/8 | Loss 2.0018091201782227]\n",
      "[Epoch 8/10 |  Step_Epoch 2/8 | Loss 1.9822455644607544]\n",
      "[Epoch 8/10 |  Step_Epoch 3/8 | Loss 1.9839555025100708]\n",
      "[Epoch 8/10 |  Step_Epoch 4/8 | Loss 1.957660436630249]\n",
      "[Epoch 8/10 |  Step_Epoch 5/8 | Loss 1.970271348953247]\n",
      "[Epoch 8/10 |  Step_Epoch 6/8 | Loss 1.9444594383239746]\n",
      "[Epoch 8/10 |  Step_Epoch 7/8 | Loss 1.9094176292419434]\n",
      "[Epoch 8/10 |  Step_Epoch 8/8 | Loss 1.9574909210205078]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 7 finished\n",
      "[Epoch 9/10 |  Step_Epoch 1/8 | Loss 1.8961100578308105]\n",
      "[Epoch 9/10 |  Step_Epoch 2/8 | Loss 1.9059983491897583]\n",
      "[Epoch 9/10 |  Step_Epoch 3/8 | Loss 1.8914990425109863]\n",
      "[Epoch 9/10 |  Step_Epoch 4/8 | Loss 1.8487606048583984]\n",
      "[Epoch 9/10 |  Step_Epoch 5/8 | Loss 1.8647505044937134]\n",
      "[Epoch 9/10 |  Step_Epoch 6/8 | Loss 1.8322279453277588]\n",
      "[Epoch 9/10 |  Step_Epoch 7/8 | Loss 1.8081445693969727]\n",
      "[Epoch 9/10 |  Step_Epoch 8/8 | Loss 1.8038668632507324]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 8 finished\n",
      "[Epoch 10/10 |  Step_Epoch 1/8 | Loss 1.8334102630615234]\n",
      "[Epoch 10/10 |  Step_Epoch 2/8 | Loss 1.788818120956421]\n",
      "[Epoch 10/10 |  Step_Epoch 3/8 | Loss 1.7570359706878662]\n",
      "[Epoch 10/10 |  Step_Epoch 4/8 | Loss 1.7210536003112793]\n",
      "[Epoch 10/10 |  Step_Epoch 5/8 | Loss 1.7481656074523926]\n",
      "[Epoch 10/10 |  Step_Epoch 6/8 | Loss 1.743739366531372]\n",
      "[Epoch 10/10 |  Step_Epoch 7/8 | Loss 1.7235617637634277]\n",
      "[Epoch 10/10 |  Step_Epoch 8/8 | Loss 1.708101749420166]\n",
      "[Step_Eval 1/2]\n",
      "[Step_Eval 2/2]\n",
      "Evaluation score for this epoch: tensor([0.0156])\n",
      "Epoch 9 finished\n",
      "Execution over\n",
      ">>> Complete execution in: 0:03:32.617487\n"
     ]
    }
   ],
   "source": [
    "!python -m plug_ai --config_file ../config_exemples/config_Brats.yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e0ecc-7533-44cf-97f3-0d103475a7b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CLI help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fa8162-f414-44e0-893c-c38bfabc0556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--dataset DATASET] [--dataset_kwargs DATASET_KWARGS]\n",
      "                   [--preprocess PREPROCESS]\n",
      "                   [--preprocess_kwargs PREPROCESS_KWARGS]\n",
      "                   [--batch_size BATCH_SIZE] [--train_ratio TRAIN_RATIO]\n",
      "                   [--val_ratio VAL_RATIO] [--limit_sample LIMIT_SAMPLE]\n",
      "                   [--shuffle SHUFFLE] [--drop_last DROP_LAST] [--model MODEL]\n",
      "                   [--model_kwargs MODEL_KWARGS] [--loop LOOP]\n",
      "                   [--loop_kwargs LOOP_KWARGS] [--nb_epoch NB_EPOCH]\n",
      "                   [--device DEVICE] [--report_log REPORT_LOG]\n",
      "                   [--criterion CRITERION]\n",
      "                   [--criterion_kwargs CRITERION_KWARGS] [--metric METRIC]\n",
      "                   [--metric_kwargs METRIC_KWARGS] [--optimizer OPTIMIZER]\n",
      "                   [--optimizer_kwargs OPTIMIZER_KWARGS]\n",
      "                   [--lr_scheduler LR_SCHEDULER]\n",
      "                   [--lr_scheduler_kwargs LR_SCHEDULER_KWARGS]\n",
      "                   [--config_file CONFIG_FILE] [--export_config EXPORT_CONFIG]\n",
      "                   [--mode MODE] [--seed SEED] [--verbose VERBOSE]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "Data arguments:\n",
      "  --dataset DATASET     A dataset name in the valid list of of datasets\n",
      "                        supported by Plug_ai\n",
      "  --dataset_kwargs DATASET_KWARGS\n",
      "                        The dictionnary of args to use that are necessary for\n",
      "                        dataset\n",
      "  --preprocess PREPROCESS\n",
      "                        A valid preprocessing pipeline name provided by\n",
      "                        plug_ai\n",
      "  --preprocess_kwargs PREPROCESS_KWARGS\n",
      "                        A dictionnary of args that are given to the processing\n",
      "                        pipeline\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Number of samples to load per batch\n",
      "  --train_ratio TRAIN_RATIO\n",
      "                        Float : The fraction of the dataset to use for\n",
      "                        training, the rest will be used for final evaluation\n",
      "  --val_ratio VAL_RATIO\n",
      "                        Float : The fraction of the train set to use for\n",
      "                        validation (hp tuning)\n",
      "  --limit_sample LIMIT_SAMPLE\n",
      "                        Index value at which to stop when considering the\n",
      "                        dataset\n",
      "  --shuffle SHUFFLE     Boolean that indicates if the dataset should be\n",
      "                        shuffled at each epoch\n",
      "  --drop_last DROP_LAST\n",
      "                        Boolean that indicates if the last batch of an epoch\n",
      "                        should be left unused when incomplete.\n",
      "\n",
      "Model arguments:\n",
      "  --model MODEL         A model in the valid list of supported model or a\n",
      "                        callable that instantiate a Pytorch/Monai model\n",
      "  --model_kwargs MODEL_KWARGS\n",
      "                        Every arguments which should be passed to the model\n",
      "                        callable\n",
      "\n",
      "Execution arguments:\n",
      "  --loop LOOP\n",
      "  --loop_kwargs LOOP_KWARGS\n",
      "  --nb_epoch NB_EPOCH\n",
      "  --device DEVICE\n",
      "  --report_log REPORT_LOG\n",
      "  --criterion CRITERION\n",
      "  --criterion_kwargs CRITERION_KWARGS\n",
      "  --metric METRIC\n",
      "  --metric_kwargs METRIC_KWARGS\n",
      "  --optimizer OPTIMIZER\n",
      "  --optimizer_kwargs OPTIMIZER_KWARGS\n",
      "  --lr_scheduler LR_SCHEDULER\n",
      "  --lr_scheduler_kwargs LR_SCHEDULER_KWARGS\n",
      "\n",
      "Global arguments:\n",
      "  --config_file CONFIG_FILE\n",
      "                        Path : The config file to set parameters more easily\n",
      "  --export_config EXPORT_CONFIG\n",
      "                        Path : If given, save the full config(combining CLI\n",
      "                        and config file) at the given path\n",
      "  --mode MODE           String : A mode between \"TRAINING\", \"EVALUATION\" and\n",
      "                        \"INFERENCE\"\n",
      "  --seed SEED           Int : If given, sets random aspect by setting random\n",
      "                        numbers generators\n",
      "  --verbose VERBOSE     String or None: The level of verbose wanted. None,\n",
      "                        \"RESTRICTED\" or \"FULL\"\n"
     ]
    }
   ],
   "source": [
    "!python -m plug_ai -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaeebab-1c70-41e2-8fcc-4f9e2e0bfc54",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test librairie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c912e38-3e6d-4c34-835b-42c833876f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utile pour recharger la librairie sans relancer le kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db1ba2-9466-42d0-b920-e10041c78d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plug_ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.10.1_py3.9.7",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.10.1_py3.9.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
