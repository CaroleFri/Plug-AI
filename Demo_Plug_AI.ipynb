{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce172f9e-3dc8-4fd4-b025-f390381438ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Pytorch & Co to Plug_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7f2c8-d7ef-4ec2-a561-38339926788d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using conventionnal Pytorch + MonAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6246509f-4684-4eab-a086-7c0095fb7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 18 01:18:33 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    74W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926023d7-699c-466b-8364-a3a6e4a449ff",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855b6d59-316d-4d61-9af6-52f00f49c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    EnsureChannelFirstd,\n",
    "    ConcatItemsd,\n",
    "    SpatialCropd,\n",
    "    AsDiscreted\n",
    ")\n",
    "from monai.data import Dataset\n",
    "\n",
    "from monai.networks.nets import DynUNet\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from torch.optim import SGD\n",
    "from monai.utils import set_determinism, first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f80e9d-99e9-45e0-a97c-32151320e402",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0b5625-9e7d-4589-bd43-eba9bb7c96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/gpfswork/rech/ibu/commun/BraTS2021/BraTS2021_Training_Data/\"\n",
    "\n",
    "def get_datalist(dataset_dir):\n",
    "    datalist = []\n",
    "    with open(os.path.join(dataset_dir, \"train.txt\"), \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            file_dic = {}\n",
    "            files = line.split()\n",
    "            for i, file in enumerate(files[:-1]):\n",
    "                file_dic[f\"channel_{i}\"] = os.path.join(dataset_dir, file)\n",
    "\n",
    "            file_dic[\"label\"] = os.path.join(dataset_dir, files[-1])\n",
    "            datalist.append(file_dic)\n",
    "    return datalist\n",
    "\n",
    "datalist = get_datalist(data_dir)\n",
    "keys = list(datalist[0].keys())\n",
    "\n",
    "transform = Compose([\n",
    "            LoadImaged(keys=keys),\n",
    "            EnsureChannelFirstd(keys=keys),\n",
    "            ConcatItemsd(keys[:-1], \"input\"),\n",
    "            SpatialCropd(keys=['input', 'label'], # crop it to make easily usable for etape 1\n",
    "                         roi_size=[128, 128, 128],\n",
    "                         roi_center=[0, 0, 0]\n",
    "                         ),\n",
    "            AsDiscreted(keys=['label'], to_onehot=5)\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Dataset(data=datalist[:20],\n",
    "                        transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c100b5-efb9-41a6-a810-66629802d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, data in enumerate(datalist:\n",
    "#    print(i, data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854fb5c-1b16-4e40-b15e-ca363d11f49a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72233d77-1f65-4045-a3ef-1f4d9daba276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=2, \n",
    "                          shuffle=True, \n",
    "                          num_workers=4,\n",
    "                         prefetch_factor=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a72bc-21c0-4800-9846-91a02b1e9282",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9042dd4-0385-483d-84c7-11046cf197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = DynUNet(spatial_dims = 3,\n",
    "                in_channels = 4,\n",
    "                out_channels = 5,\n",
    "                kernel_size = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]],\n",
    "                strides = [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n",
    "                upsample_kernel_size = [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n",
    "                norm_name = \"instance\",  # you can use fused kernel for normal layer when set to `INSTANCE_NVFUSER`\n",
    "                deep_supervision =  True,\n",
    "                deep_supr_num = 3,).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c571e552-55f1-4aae-a539-30201173810c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046dd4aa-61d3-4375-ad36-2bb0ffa83f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceCELoss(to_onehot_y=True, \n",
    "                           softmax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae0bee-0aa1-4020-ad2e-bb62b7353633",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3c7699-a14a-4787-85ed-bd91a2f3d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = DiceMetric(include_background=False, \n",
    "                    reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45384e9-6103-440d-881d-bf5db4b76323",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1f163b4-405f-42a9-b0b5-8addf8f08890",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd337f55-0c3d-4f6a-9f38-44da7aaabe13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413b885f-498f-4d60-ac64-ea67befdd7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/2\n",
      "epoch 1 average loss: 3.1551\n",
      "----------\n",
      "epoch 2/2\n",
      "epoch 2 average loss: 3.0625\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "val_interval = 2\n",
    "\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"input\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.unbind(outputs, dim=1)[0]\n",
    "        \n",
    "        labels = torch.argmax(labels, dim=1, keepdim=True)\n",
    "        loss = loss_function(outputs, labels)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        #print(f\"{step}/{len(train_dataset) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a9afe-ed3e-4afc-b8fe-10495089f256",
   "metadata": {},
   "source": [
    "## Plug_AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f8ffd-f609-4812-8469-d29243e32772",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b5193f-1b70-4725-9d9b-d5fed1b25e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writefile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7931b-2114-442d-ad7b-5ad6f84146d6",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75d64c3-5a9b-4882-bfa9-bf7a092401e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m plug_ai --config_file ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.10.1_py3.9.7",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.10.1_py3.9.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
